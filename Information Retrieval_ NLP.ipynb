{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_18231267.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandanadasarii/NLP/blob/master/Information%20Retrieval_%20NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sC-LZ20S_WUr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Information Extraction \n"
      ]
    },
    {
      "metadata": {
        "id": "9xqCFJBv_WUt",
        "colab_type": "code",
        "outputId": "cf5f2f66-f961-4b34-b3d8-f58dea382bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "# importing/downloading required packages\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "import re\n",
        "from statistics import mode"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0tGVS71YnXuH",
        "colab_type": "code",
        "outputId": "4198f637-7e53-414c-851e-2ffb085fd313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m0mo13vi_WUx",
        "colab_type": "code",
        "outputId": "8e060274-6276-4e0e-e43a-62148d259cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Loading the data and removing the empty lines in between documents\n",
        "\n",
        "inputfile=\"/content/drive/My Drive/NLP/football_players.txt\"\n",
        "buf=open(inputfile, encoding=\"UTF-8\")\n",
        "list_of_doc=buf.read().split('\\n') # Splitting based on \\n delimiter\n",
        "List=[]\n",
        "for doc in list_of_doc:\n",
        "  if len(doc)>0: # For removing empty lines in between the documents\n",
        "    List.append(doc)\n",
        "list_of_doc = List\n",
        "print(len(list_of_doc))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DCEJrJ-p_WU1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Task 1\n",
        "Write a function that takes each document and performs:\n",
        "1) sentence segmentation 2) tokenization 3) part-of-speech tagging\n",
        "\n",
        "Please keep in mind that the expected output is a list within a list as shown below.\n"
      ]
    },
    {
      "metadata": {
        "id": "U3MCJIcR_WU2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing necessary packages\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import ne_chunk\n",
        "\n",
        "def ie_preprocess(document_list):\n",
        "  pos_sentences = []\n",
        "  \n",
        "  if isinstance(document_list,list): # This check is to identify that the input parameter(document_list) is of type list or not\n",
        "    for doc in document_list:\n",
        "      sent_segment_list = sent_tokenize(doc) # Step 1 : Sentence Segmentation\n",
        "      for word in sent_segment_list:\n",
        "        words = word_tokenize(word) #Step 2: Tokenization\n",
        "        pos_sentences.append(nltk.pos_tag(words)) #  Step3 : POS tagging\n",
        "    return pos_sentences\n",
        "  \n",
        "  else: #will get here if the input parameter is not of list type\n",
        "      sent_segment_list = sent_tokenize(document_list) # Sentence Segementation\n",
        "      for word in sent_segment_list:\n",
        "        words = word_tokenize(word) # Tokenization\n",
        "        pos_sentences.append(nltk.pos_tag(words)) # Tokenization\n",
        "  return pos_sentences \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-E04CUNb_WU6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run the following code to check your result for the first document (Ronaldo)."
      ]
    },
    {
      "metadata": {
        "id": "R30taRgf_WU6",
        "colab_type": "code",
        "outputId": "ad26d2b4-fe3d-493a-e3a5-cfec5fdfb754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "cell_type": "code",
      "source": [
        "# Printing first 10 tagged and tokenized sentences from first document\n",
        "first_doc=list_of_doc[0]\n",
        "pos_sent=ie_preprocess(first_doc)\n",
        "pos_sent[0][1:20]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ronaldo', 'NNP'),\n",
              " ('dos', 'NN'),\n",
              " ('Santos', 'NNP'),\n",
              " ('Aveiro', 'NNP'),\n",
              " (',', ','),\n",
              " ('ComM', 'NNP'),\n",
              " (',', ','),\n",
              " ('GOIH', 'NNP'),\n",
              " ('(', '('),\n",
              " ('born', 'VBN'),\n",
              " ('5', 'CD'),\n",
              " ('February', 'NNP'),\n",
              " ('1985', 'CD'),\n",
              " (')', ')'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('Portuguese', 'JJ'),\n",
              " ('professional', 'JJ'),\n",
              " ('footballer', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "OMw70Wm8_WU-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Expected output\n",
        " [...[('He', 'PRP'),\n",
        "  ('is', 'VBZ'),\n",
        "  ('a', 'DT'),\n",
        "  ('forward', 'NN'),\n",
        "  ('and', 'CC'),\n",
        "  ('serves', 'NNS'),\n",
        "  ('as', 'IN'),\n",
        "  ('captain', 'NN'),\n",
        "  ('for', 'IN'),\n",
        "  ('Portugal', 'NNP'),\n",
        "  ('.', '.')], ...]"
      ]
    },
    {
      "metadata": {
        "id": "tYTwrZId_WU_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Task 2 \n",
        "Write a function that will take the list of tokens with POS tags for each sentence and returns the named entities (NE). \n",
        "\n",
        "Hint: Use binary=True while calling NE chunk function"
      ]
    },
    {
      "metadata": {
        "id": "5fC0iqJJ_WU_",
        "colab_type": "code",
        "outputId": "8e3d5f1d-c2c8-4485-c585-0b39513dab37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "cell_type": "code",
      "source": [
        "def named_entity_finding(pos_sent):\n",
        "    \n",
        "    tree = nltk.ne_chunk(pos_sent, binary=True)\n",
        "    named_entities = []\n",
        "    for subtree in tree.subtrees():\n",
        "      if subtree.label() == 'NE':\n",
        "        entity = \"\"\n",
        "        for leaf in subtree.leaves():\n",
        "          entity = entity + leaf[0] + \" \"\n",
        "        named_entities.append(entity.strip())\n",
        "    return named_entities\n",
        "\n",
        "#For printing Named Entities in the first sentence of first document\n",
        "\n",
        "pos_sents=ie_preprocess(list_of_doc[0])\n",
        "named_entity_finding(pos_sents[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cristiano Ronaldo',\n",
              " 'Santos Aveiro',\n",
              " 'ComM',\n",
              " 'GOIH',\n",
              " 'Portuguese',\n",
              " 'Spanish',\n",
              " 'Real Madrid',\n",
              " 'Portugal']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "fDolbFKE_WVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Expected output ['Cristiano Ronaldo',\n",
        " 'Santos Aveiro',\n",
        " 'ComM',\n",
        " 'GOIH',\n",
        " 'Portuguese',\n",
        " 'Portuguese',\n",
        " 'Spanish',\n",
        " 'Real Madrid',\n",
        " 'Portugal']"
      ]
    },
    {
      "metadata": {
        "id": "XHMp7xtK_WVE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Task 3\n",
        "\n",
        "Now use the named_entity_finding() function to extract all NEs for each document.\n",
        "\n",
        "Hint: pos_sents holds the list of lists of tokens with POS tags"
      ]
    },
    {
      "metadata": {
        "id": "TwFlzQx4_WVF",
        "colab_type": "code",
        "outputId": "883aae67-3e10-4006-aaa6-87d61fc84607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "def NE_flat_list_fn(pos_sents): \n",
        "    NE=[]\n",
        "    NE_flat_list =[]\n",
        "    for pos_sent in pos_sents:\n",
        "      NE.append(named_entity_finding(pos_sent)) # Calling the funtion named_entity_finding(pos_sent) and appending the result to the NE list\n",
        "      NE_flat_list = [item for sublist in NE for item in sublist] #Flatten the list of lists to the single list NE_flat_list\n",
        "    return NE_flat_list\n",
        "  \n",
        "  \n",
        "# Printing named entities present in all sentences of all the documents.\n",
        "\n",
        "pos_sents=ie_preprocess(list_of_doc)\n",
        "NE_flat_list_fn(pos_sents)[0:10]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cristiano Ronaldo',\n",
              " 'Santos Aveiro',\n",
              " 'ComM',\n",
              " 'GOIH',\n",
              " 'Portuguese',\n",
              " 'Spanish',\n",
              " 'Real Madrid',\n",
              " 'Portugal',\n",
              " 'Portugal',\n",
              " 'Ballon']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "l7-ma9lJ_WVJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Task 4 \n",
        "\n",
        "Write functions to extract the name of the player, country of origin and date of birth as well as the following relations: team(s) of the player and position(s) of the player.\n",
        "\n",
        "Hint: Use the re.compile() function to create the extraction patterns\n",
        "\n",
        "Reference: https://docs.python.org/3/howto/regex.html"
      ]
    },
    {
      "metadata": {
        "id": "cH1TdvKwMwRC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Explanation for Extracting the Name of the player :\n",
        "\n",
        "For Extracting the name of the player i have listed two methods.\n",
        "\n",
        "  **Using the Regular expressions** :\n",
        "\n",
        "For each document i observed some pattern with the name of the player. Which is name of the player will be in the starting of the first sentence in that docuemnt. So accordingly\n",
        "I have used the regular expression **name_re= re.compile(r'^.[^,(]*')** \n",
        "which means from the start of the document search for the pattern which  starts with any character appearing any number of times till the first time \",\" or  \"(\" encounters.\n",
        "\n",
        "Its capturing the complete name.\n",
        "\n",
        "For Example : Cristiano Ronaldo dos Santos Aveiro\n",
        "\n",
        "**  Using the Named Entity recognition** :\n",
        "\n",
        "For this i have used the named_entity_finding() function which is defined above. \n",
        "\n",
        "Output : Its not always  capturing the complete name .\n",
        "\n",
        "For Example : It could only able to capture \"Cristiano Ronaldo\" rather than  his complete name \"Cristiano Ronaldo dos Santos Aveiro\"\n",
        "\n",
        "Reason : we are using named_entity_finding() function  to extract the name of the player , Which works based on the POS tagging, It basically identifies the Named entities if the sequential words tags equals to NNP.\n",
        "\n",
        "[('Cristiano', 'NNP'), ('Ronaldo', 'NNP'), ('dos', 'NN'), ('Santos', 'NNP'), ('Aveiro', 'NNP')] - In this case it could only captures the name of the player till Cristiano Ronaldo\n",
        "\n",
        "Where as in the below case\n",
        "[('David', 'NNP'), ('Robert', 'NNP'), ('Joseph', 'NNP'), ('Beckham', 'NNP')] - It captures the complete name because of continuous NNP tags.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "tbaFyiah_WVK",
        "colab_type": "code",
        "outputId": "33833622-e9a5-4192-8d36-0b35267d96a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "import re, nltk\n",
        "\n",
        "def name_of_the_player(doc):\n",
        "      name_re= re.compile(r'^.[^,(]*') # Regular expression which captures the document start till \" , \" or \" ( \"  encounters.\n",
        "      name=name_re.findall(doc)        #findall matches all the matches which satisfy the regular expression\n",
        "      return name[0]                   # returning the first match\n",
        "\n",
        "# printing name of the player for each document  \n",
        "for i in range(len(list_of_doc)):\n",
        "  print(name_of_the_player(list_of_doc[i]))\n",
        "  \n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cristiano Ronaldo dos Santos Aveiro\n",
            "Lionel Andrés \"Leo\" Messi \n",
            "Neymar da Silva Santos Júnior \n",
            "Ronaldo de Assis Moreira \n",
            "Wayne Mark Rooney \n",
            "Zlatan Ibrahimović \n",
            "David Robert Joseph Beckham\n",
            "Mesut Özil \n",
            "Gareth Frank Bale \n",
            "Andrés Iniesta Luján \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M7uyXjNpo_BI",
        "colab_type": "code",
        "outputId": "4321fce9-5840-451a-8e6f-bb88bb1c291d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "# This is another method for capturing the name of the player using Named Entities.\n",
        "#But sometimes its not capturing the Complete name that is the reason i have captured the names using the regular expressions\n",
        "\n",
        "def name_of_the_player_function2(doc):\n",
        "      pos_sents=ie_preprocess(doc)\n",
        "      name=named_entity_finding(pos_sents[0]) # calling the named_entity_finding function defined above\n",
        "      return name[0]\n",
        "\n",
        "# Printing name of the player for each document\n",
        "for i in range(len(list_of_doc)):\n",
        "  print(name_of_the_player_function2(list_of_doc[i]))\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cristiano Ronaldo\n",
            "Lionel Andrés\n",
            "Neymar\n",
            "Ronaldo\n",
            "Wayne Mark Rooney\n",
            "Zlatan Ibrahimović\n",
            "David Robert Joseph Beckham\n",
            "Mesut Özil\n",
            "Gareth Frank Bale\n",
            "Andrés Iniesta Luján\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X8R5mZ8ySNu1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Explanation for extracting the country of origin: \n",
        "country_of_origin  extracted using the regular expression $'the (\\w+\\s)(?:national \\;team)'$\n",
        "Which means extracting a word which starts with \"the\" and followed by \\w+ matches any word character (equal to [a-zA-Z0-9_]) phrase.\n",
        "\n",
        "\"+\" Quantifier — Matches between one and unlimited times, as many times as possible, giving back as needed (greedy)\n",
        "\n",
        "\"\\s\" matches any whitespace character (equal to [\\r\\n\\t\\f\\v ])\n",
        "\n",
        " **Capturing Group** :  (\\w+\\s)\n",
        "\n",
        "**Non-capturing group**  : (?:national team)\n",
        "national team matches the characters national team literally (case sensitive)"
      ]
    },
    {
      "metadata": {
        "id": "-6o_zAPQ14IN",
        "colab_type": "code",
        "outputId": "434110bb-f15b-4b18-f9eb-1b6a769dc5ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "# COUNTRY NAME\n",
        "def country_of_origin(doc):\n",
        "  country_re= re.compile(r'the (\\w+\\s)(?:national team)')\n",
        "  matches = country_re.findall(doc)\n",
        "  country= matches[0]\n",
        "  return country\n",
        "\n",
        "#Printing Country of the Origin for each document\n",
        "for i in range(len(list_of_doc)):\n",
        "  print(\"document \", i, country_of_origin(list_of_doc[i]))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "document  0 Portugal \n",
            "document  1 Argentina \n",
            "document  2 Brazil \n",
            "document  3 Brazil \n",
            "document  4 England \n",
            "document  5 Sweden \n",
            "document  6 England \n",
            "document  7 German \n",
            "document  8 Wales \n",
            "document  9 Spain \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p2HMf_Z9UjCL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Explanation for extracting the date of birth:\n",
        "\n",
        "\n",
        "This can be extracted using the regular expression  $born\\s(.*?)(?:\\))$\n",
        "\n",
        "born matches the characters born literally (case sensitive)\n",
        "\n",
        "\"\\s\" matches any whitespace character (equal to [\\r\\n\\t\\f\\v ])\n",
        "\n",
        "\"*?\" Quantifier — Matches between zero and unlimited times, as few times as possible, expanding as needed (lazy)\n",
        "\n",
        "**Capturing Group ** : (.*?)\n",
        "\n",
        "which means that extracting the words/phrases which starts with the and followed by the first $)$ encountered.\n",
        "\n",
        "**Non-capturing group (?:\\))**\n",
        "\n",
        "\\) matches the character ) literally (case sensitive)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4UNP4NP0DGHg",
        "colab_type": "code",
        "outputId": "51f90e59-dea4-49d1-dd01-f3f20483b3d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "def date_of_birth(doc):\n",
        "  born_re = re.compile(r'born\\s(.*?)(?:\\))')\n",
        "  matches=born_re.findall(doc)\n",
        "  date=matches[0]\n",
        "  return date\n",
        "\n",
        "# Printing dob for all the documents\n",
        "for i in range(len(list_of_doc)):\n",
        "  print(date_of_birth(list_of_doc[i]))\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 February 1985\n",
            "24 June 1987\n",
            "5 February 1992\n",
            "21 March 1980\n",
            "24 October 1985\n",
            "3 October 1981\n",
            "2 May 1975\n",
            "15 October 1988\n",
            "16 July 1989\n",
            "11 May 1984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7g3p6CcQ_WVS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Expected output '5 February 1992'"
      ]
    },
    {
      "metadata": {
        "id": "55w8Vh6RxXmo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "###Gazetteer :\n",
        "\n",
        "A gazetteer consists of a set of lists containing names of entities such as cities, organisations, days of the week, etc. These lists are used to ﬁnd occurrences of these names in text\n",
        "Example : .named entity recognition task\n",
        "\n",
        "### Gazetter method :\n",
        "As there are multiple but finite set of teams for each player i have used this approach for capturing all the teams of the player.\n",
        "\n",
        "For creating the Gazetteer list i have taken all the  clubs/ teams in football from the wikipedia source.\n",
        "\n",
        "### Regular expression method :\n",
        "I have tried capturing all the teams using the regular expression method too, as its following different variety of patterns in teams  i coudn't capture all the teams."
      ]
    },
    {
      "metadata": {
        "id": "S2d7FbR3DHBj",
        "colab_type": "code",
        "outputId": "bade65fe-1ee3-498b-954b-357be99eeddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "def team_of_the_player(doc):\n",
        "  \n",
        "  national_team_re = re.compile(r'the (\\w+\\snational team)') #this re for finding national teams\n",
        "  \n",
        "  #defined teams_gazetteer \n",
        "  teams_gazetteer = ['A.C. Milan','AFC Ajax Amsterdam',\n",
        "    'Ajax',\n",
        "    'América',\n",
        "    'Arsenal',\n",
        "    'AS Monaco',\n",
        "    'Atlas',\n",
        "    'Atlético Mineiro',\n",
        "    'Atlético Paranaense',\n",
        "    'Atlético River Plate',\n",
        "    'Bahia',\n",
        "    'Bangu',\n",
        "    'Bayer Leverkusen',\n",
        "    'Belenenses',\n",
        "    'Benfica',\n",
        "    'Benfica',\n",
        "    'Boavista',\n",
        "    'Boca Juniors',\n",
        "    'Borussia Dortmund',\n",
        "    'Botafogo',\n",
        "    'Braga',\n",
        "    'Bragantino',\n",
        "    'BUAP',\n",
        "    'Celtic - Scotland',\n",
        "    'Chaves',\n",
        "    'Chelsea',\n",
        "    'Chivas de Guadalajara',\n",
        "    'Club América',\n",
        "    'Club Brugge - Belgium',\n",
        "    'Corinthians',\n",
        "    'Corinthians',\n",
        "    'Coritiba',\n",
        "    'Cruz Azul',\n",
        "    'Cruzeiro',\n",
        "    'CSKA Moscow - Russia',\n",
        "    'D.C. United',\n",
        "    'Desportivo das Aves',\n",
        "    'Dinamo Zagreb - Croatia',\n",
        "    'Everton',\n",
        "    'FC Barcelona',\n",
        "    'FC Bayern München',\n",
        "    'FC Porto',\n",
        "    'Feirense',\n",
        "    'Feyenoord Rotterdam',\n",
        "    'Flamengo',\n",
        "    'Flamengo',\n",
        "    'Fluminense',\n",
        "    'Fortaleza',\n",
        "    'Grasshopperclub Zurich - Switzerland',\n",
        "    'Grêmio',\n",
        "    'Guadalajara',\n",
        "    'Guarani',\n",
        "    'Inter Milan',\n",
        "    'Internacional',\n",
        "    'Juventus',\n",
        "    'Kerala Blasters',\n",
        "    'LA Galaxy',\n",
        "    'León',\n",
        "    'Liverpool',\n",
        "    'Los Angeles Galaxy',\n",
        "    'Manchester United',\n",
        "    'Malmö FF',\n",
        "    'Marítimo',\n",
        "    'Milan',\n",
        "    'Monterrey',\n",
        "    'Moreirense',\n",
        "    'Morelia',\n",
        "    'Nacional',\n",
        "    'Náutico',\n",
        "    'Necaxa',\n",
        "    'Olympiacos - Greece',\n",
        "    'Olympique de Marseille',\n",
        "    'Olympique Lyonnais',\n",
        "    'Pachuca',\n",
        "    'Palmeiras',\n",
        "    'Palmeiras',\n",
        "    'Panathinaikos - Greece',\n",
        "    'Paris Saint-Germain',\n",
        "    'Portimonense',\n",
        "    'Porto',\n",
        "    'Portuguesa',\n",
        "    'Preston North End',\n",
        "    'PSV Eindhoven',\n",
        "    'Puebla',\n",
        "    'Querétaro',\n",
        "    'Rangers - Scotland',\n",
        "    'Real Madrid',\n",
        "    'Rio Ave',\n",
        "    'RSC Anderlecht - Belgium',\n",
        "    'Santa Clara',\n",
        "    'Santos Laguna',\n",
        "    'Santos',\n",
        "    'Santos',\n",
        "    'São Caetano',\n",
        "    'São Paulo',\n",
        "    'São Paulo',\n",
        "    'Schalke',\n",
        "    'Shakhtar Donetsk - Ukraine',\n",
        "    'Southampton',\n",
        "    'Sport Recife',\n",
        "    'Sporting CP',\n",
        "    'Sporting Lisbon',\n",
        "    'Steaua Bucharest - Romania',\n",
        "    'SV Werder Bremen',\n",
        "    'Tijuana',\n",
        "    'Toluca',\n",
        "    'Tondela',\n",
        "    'Tottenham Hotspur',\n",
        "    'UANL',\n",
        "    'UNAM',\n",
        "    'Vasco',\n",
        "    'Veracruz',\n",
        "    'Vitória de Guimarães',\n",
        "    'Vitória de Setúbal',\n",
        "    'Vitória',\n",
        "    'Werder Bremen',\n",
        "]\n",
        "  \n",
        "  teams_re = \"\"\n",
        "  for team in teams_gazetteer:\n",
        "    teams_re = teams_re+\"|\"+ team # Building the regular expression from the Gazetteer list\n",
        "  teams_re=teams_re[1:]           # removing the first \"|\" from regular expression \n",
        "  \n",
        "  matches = re.compile(teams_re).findall(doc)\n",
        "  \n",
        "\n",
        "  \n",
        "  if(len(matches)>0):\n",
        "    teams = list(set(matches))\n",
        "    nat_matches=national_team_re.findall(doc)\n",
        "    teams.append(nat_matches[0])\n",
        "    return teams\n",
        "  \n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# For printing teams of all the players\n",
        "for i in range(len(list_of_doc)):\n",
        "  print(\"document \", i, team_of_the_player(list_of_doc[i]))\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "document  0 ['Manchester United', 'Sporting CP', 'Real Madrid', 'Santos', 'Portugal national team']\n",
            "document  1 ['FC Barcelona', 'América', 'Argentina national team']\n",
            "document  2 ['FC Barcelona', 'Santos', 'América', 'Brazil national team']\n",
            "document  3 ['Flamengo', 'FC Barcelona', 'Milan', 'Atlético Mineiro', 'Querétaro', 'Paris Saint-Germain', 'Grêmio', 'Brazil national team']\n",
            "document  4 ['Everton', 'Manchester United', 'England national team']\n",
            "document  5 ['Milan', 'A.C. Milan', 'Malmö FF', 'Manchester United', 'Ajax', 'Juventus', 'Paris Saint-Germain', 'Inter Milan', 'Sweden national team']\n",
            "document  6 ['LA Galaxy', 'Milan', 'Manchester United', 'Paris Saint-Germain', 'Real Madrid', 'Preston North End', 'England national team']\n",
            "document  7 ['Arsenal', 'Werder Bremen', 'Schalke', 'Real Madrid', 'German national team']\n",
            "document  8 ['Southampton', 'Real Madrid', 'Tottenham Hotspur', 'Wales national team']\n",
            "document  9 ['FC Barcelona', 'Spain national team']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fUv8-28vVWQP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Explanation for extracting the position of the player :\n",
        "\n",
        "To extract the position information , i have created a list with all possible positions as positions are limited in number which is nothing but a **position_gazetteer**\n",
        "And created a regular expression which matches with any of the positions mentioned in that list and returns it.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0u1-F-9OQ3kZ",
        "colab_type": "code",
        "outputId": "a1be7f1d-0b95-4789-be59-973f00065231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "def position_of_the_player(doc):\n",
        "  \n",
        "  #This is the standard positions list for football \n",
        "  # Defined the position Gazetteer\n",
        "  position_gazetteer = [\"forward\",\"striker\",\"winger\",\"centre-back\",\n",
        "                       \"sweeper\",\"full-back\",\"wing-back\",\n",
        "                       \"center midfield\",\"central midfield\",\n",
        "                       \"goalkeeper\",\"defensive midfield\",\"attacking midfield\",\n",
        "                       \"wide midfield\",\"centre forward\"]\n",
        "  positions_re = \"\"\n",
        "  \n",
        "  for pos in position_gazetteer:\n",
        "    positions_re = positions_re+\"|\"+pos # Building the regular expression from the position_gazetteer\n",
        "  positions_re=positions_re[1:]\n",
        "  \n",
        "  matches = re.compile(positions_re).findall(doc) # Finding the matches\n",
        "\n",
        "  if(len(matches)>0):\n",
        "    position = list(set(matches)) # filtering the unique list of positions for each player\n",
        "    return position\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "  \n",
        "# Printing the player positions for each document\n",
        "for i in range(len(list_of_doc)):\n",
        "  print(\"document \", i, position_of_the_player(list_of_doc[i]))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "document  0 ['forward']\n",
            "document  1 ['forward']\n",
            "document  2 ['forward']\n",
            "document  3 ['attacking midfield', 'forward']\n",
            "document  4 ['forward']\n",
            "document  5 ['striker']\n",
            "document  6 ['winger']\n",
            "document  7 ['attacking midfield']\n",
            "document  8 ['winger']\n",
            "document  9 ['central midfield']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qZAyfxNXV8GL",
        "colab_type": "code",
        "outputId": "44a46a49-16cf-4269-8deb-531c0ce5a58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Run all the functions above before running this\n",
        "\n",
        "def Players_Data(doc):\n",
        "  \n",
        "  data = [name_of_the_player(doc), date_of_birth(doc), country_of_origin(doc), position_of_the_player(doc), team_of_the_player(doc)]\n",
        "    \n",
        "  return data\n",
        "\n",
        "\n",
        "# Printing all the above extracted data for each player.\n",
        "for i in range(len(list_of_doc)):\n",
        "  print(\"document \", i, Players_Data(list_of_doc[i]))\n",
        "\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "document  0 ['Cristiano Ronaldo dos Santos Aveiro', '5 February 1985', 'Portugal ', ['forward'], ['Manchester United', 'Sporting CP', 'Real Madrid', 'Santos', 'Portugal national team']]\n",
            "document  1 ['Lionel Andrés \"Leo\" Messi ', '24 June 1987', 'Argentina ', ['forward'], ['FC Barcelona', 'América', 'Argentina national team']]\n",
            "document  2 ['Neymar da Silva Santos Júnior ', '5 February 1992', 'Brazil ', ['forward'], ['FC Barcelona', 'Santos', 'América', 'Brazil national team']]\n",
            "document  3 ['Ronaldo de Assis Moreira ', '21 March 1980', 'Brazil ', ['attacking midfield', 'forward'], ['Flamengo', 'FC Barcelona', 'Milan', 'Atlético Mineiro', 'Querétaro', 'Paris Saint-Germain', 'Grêmio', 'Brazil national team']]\n",
            "document  4 ['Wayne Mark Rooney ', '24 October 1985', 'England ', ['forward'], ['Everton', 'Manchester United', 'England national team']]\n",
            "document  5 ['Zlatan Ibrahimović ', '3 October 1981', 'Sweden ', ['striker'], ['Milan', 'A.C. Milan', 'Malmö FF', 'Manchester United', 'Ajax', 'Juventus', 'Paris Saint-Germain', 'Inter Milan', 'Sweden national team']]\n",
            "document  6 ['David Robert Joseph Beckham', '2 May 1975', 'England ', ['winger'], ['LA Galaxy', 'Milan', 'Manchester United', 'Paris Saint-Germain', 'Real Madrid', 'Preston North End', 'England national team']]\n",
            "document  7 ['Mesut Özil ', '15 October 1988', 'German ', ['attacking midfield'], ['Arsenal', 'Werder Bremen', 'Schalke', 'Real Madrid', 'German national team']]\n",
            "document  8 ['Gareth Frank Bale ', '16 July 1989', 'Wales ', ['winger'], ['Southampton', 'Real Madrid', 'Tottenham Hotspur', 'Wales national team']]\n",
            "document  9 ['Andrés Iniesta Luján ', '11 May 1984', 'Spain ', ['central midfield'], ['FC Barcelona', 'Spain national team']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sCYflDpp_WVU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Task 5\n",
        "Write a function using the outputs from the previous functions to generate JSON-LD output as follows.\n",
        "\n",
        "Reference: https://json-ld.org/primer/latest/\n",
        "\n",
        "{ \"@id\": \"http://my-soccer-ontology.com/footballer/name_of_the_player\",\n",
        "\n",
        "    \"name\": \"\",\n",
        "    \"born\": \"\",\n",
        "    \"country\": \"\",\n",
        "    \"position\": [\n",
        "        { \"@id\": \"http://my-soccer-ontology.com/position\",\n",
        "            \"type\": \"\"\n",
        "        }\n",
        "     ]   \n",
        "     \"team\": [\n",
        "        { \"@id\": \"http://my-soccer-ontology.com/team\",\n",
        "            \"name\": \"\"\n",
        "        }   \n",
        "     ]\n",
        "}\n"
      ]
    },
    {
      "metadata": {
        "id": "z8HStdlu_WVU",
        "colab_type": "code",
        "outputId": "498f98fc-bc78-4104-ebd7-8bc649f0bc21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def generate_jsonId(doc):\n",
        "  \n",
        "  player_info = dict()\n",
        "  player_info [\"@id\"] = \"http://my-soccer-ontology.com/footballer/name\"\n",
        "  player_info[\"name\"] = name_of_the_player(doc)\n",
        "  player_info[\"born\"] =  date_of_birth(doc)\n",
        "  player_info[\"country\"] = country_of_origin(doc)\n",
        "  \n",
        "  positions = position_of_the_player(doc)\n",
        "  player_info[\"positions\"] = []\n",
        "  \n",
        "  for position in positions:\n",
        "    pos = dict()\n",
        "    pos[\"@id\"] = \"http://my-soccer-ontology.com/position\"\n",
        "    pos[\"type\"] = position\n",
        "    player_info[\"positions\"].append(pos)\n",
        "  \n",
        "  teams = team_of_the_player(doc)\n",
        "  player_info[\"team\"] = []\n",
        "  \n",
        "  for t in teams:\n",
        "    team = dict()\n",
        "    team[\"@id\"] = \"http://my-soccer-ontology.com/team\"\n",
        "    team[\"name\"] = t\n",
        "    player_info[\"team\"].append(team)\n",
        "  \n",
        "  return player_info\n",
        "\n",
        "# printing \n",
        "print(json.dumps(generate_jsonId(list_of_doc[0]), indent=2))\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"@id\": \"http://my-soccer-ontology.com/footballer/name\",\n",
            "  \"name\": \"Cristiano Ronaldo dos Santos Aveiro\",\n",
            "  \"born\": \"5 February 1985\",\n",
            "  \"country\": \"Portugal \",\n",
            "  \"positions\": [\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/position\",\n",
            "      \"type\": \"forward\"\n",
            "    }\n",
            "  ],\n",
            "  \"team\": [\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/team\",\n",
            "      \"name\": \"Manchester United\"\n",
            "    },\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/team\",\n",
            "      \"name\": \"Sporting CP\"\n",
            "    },\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/team\",\n",
            "      \"name\": \"Real Madrid\"\n",
            "    },\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/team\",\n",
            "      \"name\": \"Santos\"\n",
            "    },\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/team\",\n",
            "      \"name\": \"Portugal national team\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i3VtWxBr_WVZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Task 6\n",
        "Identify one other relation (besides team and player) and write a function to extract this. Also extend the JSON-LD output accordingly.\n",
        "\n",
        "##Extracting Debut Year && Debut Age :\n",
        "\n",
        "I would like to extract the **Debut Year and Debut Age** of the each player. \n",
        "\n",
        "But as this information is not present for all the players.   and in some cases only one of the information in Debut year and Debut age are present.\n",
        "\n",
        "So, I have used some simple calculations  to fill the debut year from the debut age and vice versa.\n",
        "\n",
        "### Steps followed in filling the debut year from the debut age and vice versa :\n",
        "\n",
        "1. If only debut age is present , Exracted the debut year as follows :\n",
        "\n",
        "\n",
        "*   Using the date_of_birth() function extracted the birth year(Using the regular expressions)\n",
        "*   By adding the Birth year and Debut age calculated the Debut year\n",
        "\n",
        "\n",
        "2. If only debut year is present , Extracted the debut age as follows :  \n",
        "      \n",
        "\n",
        "\n",
        "*   Using the date_of_birth() function extracted the birth year(Using the regular expressions)\n",
        "*   By Substracting  the Birth year from  Debut year calculated the Debut age\n",
        "\n",
        "\n",
        "\n",
        "3. For the players who doesnt have neither of the information i have added the \"NA\"(Not Available) in the result."
      ]
    },
    {
      "metadata": {
        "id": "TR0GZrUB_WVa",
        "colab_type": "code",
        "outputId": "6ffddc63-0c33-48bc-f984-68f0adce30c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "def debut_info_of_the_player(doc):\n",
        "  \n",
        "  debutyear_re= re.compile(r'debut in (\\d{4})') # Regular expression for capturing the debut year\n",
        "  debutage_re = re.compile(r'(?:age\\s|aged\\s)([\\d]+)') # Regular expression for capturing the debut age\n",
        "  matches_age = debutage_re.findall(doc)\n",
        "  matches_year = debutyear_re.findall(doc)\n",
        "  year = 0\n",
        "  age =0\n",
        "  l=[] \n",
        "  # Appedning the debut year and debut age information to the list\n",
        "  if len(matches_year)>0:\n",
        "    year= matches_year[0]\n",
        "    l.append(year) \n",
        "  else:\n",
        "    l.append(\"NA\")\n",
        "  \n",
        "  if len(matches_age)>0:\n",
        "    age= matches_age[0]\n",
        "    l.append(age)\n",
        "  else:\n",
        "    l.append(\"NA\")\n",
        "    \n",
        "  if l[0]==\"NA\":\n",
        "    if l[1] != \"NA\":   # case when debut year is not present and debut age is present\n",
        "      dob=date_of_birth(doc)\n",
        "      dob_re = re.compile(r'\\d{4}') # regular expression for extracting the bth year\n",
        "      dob_year= dob_re.findall(dob)\n",
        "      year = int(dob_year[0]) + int(l[1])  # Calculating the debut year from the debut age and birth year\n",
        "      l[0] = year\n",
        "  else:\n",
        "    if l[1] == \"NA\":    # case when debut year is present and debut age is not present\n",
        "      dob=date_of_birth(doc)\n",
        "      dob_re = re.compile(r'\\d{4}') # RE for extracting the birth year\n",
        "      dob_year= dob_re.findall(dob)\n",
        "      age = int(l[0]) - int(dob_year[0]) #Calculating the debut age from birth year and debut year\n",
        "      l[1] = age\n",
        "      \n",
        "  return l\n",
        "\n",
        "\n",
        "# For printing  \n",
        "for i in range(len(list_of_doc)):\n",
        "  print(\"document \", i, debut_info_of_the_player(list_of_doc[i]))\n",
        "  \n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "document  0 [2003, '18']\n",
            "document  1 [2000, '13']\n",
            "document  2 [2009, '17']\n",
            "document  3 ['NA', 'NA']\n",
            "document  4 ['2002', '17']\n",
            "document  5 ['2001', 20]\n",
            "document  6 ['1992', '17']\n",
            "document  7 ['NA', 'NA']\n",
            "document  8 ['NA', 'NA']\n",
            "document  9 ['2006', '18']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0KbW9LLA7t1a",
        "colab_type": "code",
        "outputId": "09c5a922-d42c-4850-812c-e9de84effd98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def generate_jsonId(doc):\n",
        "  \n",
        "  player_info = dict()\n",
        "  player_info [\"@id\"] = \"http://my-soccer-ontology.com/footballer/name\"\n",
        "  player_info[\"name\"] = name_of_the_player(doc)\n",
        "  player_info[\"born\"] =  date_of_birth(doc)\n",
        "  player_info[\"country\"] = country_of_origin(doc)\n",
        "  \n",
        "  \n",
        "  positions = position_of_the_player(doc)\n",
        "  player_info[\"positions\"] = []\n",
        "  \n",
        "  for position in positions:\n",
        "    pos = dict()\n",
        "    pos[\"@id\"] = \"http://my-soccer-ontology.com/position\"\n",
        "    pos[\"type\"] = position\n",
        "    player_info[\"positions\"].append(pos)\n",
        "  \n",
        "  teams = team_of_the_player(doc)\n",
        "  player_info[\"team\"] = []\n",
        "  \n",
        "  for t in teams:\n",
        "    team = dict()\n",
        "    team[\"@id\"] = \"http://my-soccer-ontology.com/team\"\n",
        "    team[\"name\"] = t\n",
        "    player_info[\"team\"].append(team)\n",
        "  \n",
        "  # Adding the debut information\n",
        "  \n",
        "  player_info[\"debut_Information\"] = {\"Debut year\" : debut_info_of_the_player(doc)[0],\n",
        "                                      \"Debut Age\" : debut_info_of_the_player(doc)[1]} \n",
        "  \n",
        "  \n",
        "  return player_info\n",
        "\n",
        "# printing \n",
        "print(json.dumps(generate_jsonId(list_of_doc[0]), indent=2))\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"@id\": \"http://my-soccer-ontology.com/footballer/name\",\n",
            "  \"name\": \"Cristiano Ronaldo dos Santos Aveiro\",\n",
            "  \"born\": \"5 February 1985\",\n",
            "  \"country\": \"Portugal \",\n",
            "  \"positions\": [\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/position\",\n",
            "      \"type\": \"forward\"\n",
            "    }\n",
            "  ],\n",
            "  \"team\": [\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/team\",\n",
            "      \"name\": \"Manchester United\"\n",
            "    },\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/team\",\n",
            "      \"name\": \"Sporting CP\"\n",
            "    },\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/team\",\n",
            "      \"name\": \"Real Madrid\"\n",
            "    },\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/team\",\n",
            "      \"name\": \"Santos\"\n",
            "    },\n",
            "    {\n",
            "      \"@id\": \"http://my-soccer-ontology.com/team\",\n",
            "      \"name\": \"Portugal national team\"\n",
            "    }\n",
            "  ],\n",
            "  \"debut_Information\": {\n",
            "    \"Debut year\": 2003,\n",
            "    \"Debut Age\": \"18\"\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}